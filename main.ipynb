{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c6548ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def open_filepath(filePath):\n",
    "    try:\n",
    "        abs_path = Path(os.path.abspath(filePath))\n",
    "        with open(abs_path, \"r\") as file:\n",
    "            lines_list = file.readlines()\n",
    "            return lines_list\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {abs_path}\")\n",
    "        print(f\"Current working directory: {os.getcwd()}\")\n",
    "    return []\n",
    "\n",
    "def separate_sequences(filepath):\n",
    "    res = []\n",
    "    text = open_filepath(filepath)\n",
    "    curr_seq = []\n",
    "    for line in text:\n",
    "        if line == '\\n':\n",
    "            if curr_seq:\n",
    "                res.append(curr_seq)\n",
    "            curr_seq = []\n",
    "        else:\n",
    "            curr_seq.append(line.strip('\\n'))\n",
    "    if curr_seq:\n",
    "        res.append(curr_seq)\n",
    "    return res\n",
    "\n",
    "def separate_observation_label(filepath):\n",
    "    data = separate_sequences(filepath)\n",
    "    return [[line.split() for line in seq] for seq in data]\n",
    "\n",
    "train_data = separate_observation_label(\"EN/train\")\n",
    "dev_in_data = separate_sequences(\"EN/dev.in\")\n",
    "dev_out_data = separate_observation_label(\"EN/dev.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9822c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_mle(data: list[list[tuple[str, str]]]) -> dict:\n",
    "    emission_prob = {}\n",
    "    tags = {}\n",
    "    for seq in data:\n",
    "        for word, tag in seq:\n",
    "            if tag not in tags:\n",
    "                tags[tag] = {\"count\": 0, \"words\": {}}\n",
    "            tags[tag][\"count\"] += 1\n",
    "            tags[tag][\"words\"][word] = tags[tag][\"words\"].get(word, 0) + 1\n",
    "    for tag in tags:\n",
    "        emission_prob[tag] = {}\n",
    "        for word in tags[tag][\"words\"]:\n",
    "            emission_prob[tag][word] = tags[tag][\"words\"][word] / tags[tag][\"count\"]\n",
    "    return emission_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "342e4a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data: list[list[tuple[str, str]]], k: int = 3) -> dict:\n",
    "    UNK = \"#UNK#\"\n",
    "    tags = {}\n",
    "    replaced = {}\n",
    "    res_data = []\n",
    "\n",
    "    for seq in data:\n",
    "        for word,tag in seq:\n",
    "            if tag not in tags:\n",
    "                tags[tag] = {}\n",
    "            tags[tag][word] = tags[tag].get(word, 0) + 1\n",
    "\n",
    "    for tag in tags:\n",
    "        if tag not in replaced:\n",
    "            replaced[tag] = set()\n",
    "        for word in tags[tag]:\n",
    "            if tags[tag][word] < k:\n",
    "                replaced[tag].add(word)\n",
    "\n",
    "    for seq in data:\n",
    "        smooth_seq = list()\n",
    "        for i in range(len(seq)):\n",
    "            tag = seq[i][1]\n",
    "            word = UNK if seq[i][0] in replaced[tag] else seq[i][0]\n",
    "            smooth_seq.append((word, tag))\n",
    "        res_data.append(smooth_seq)\n",
    "    return res_data\n",
    "\n",
    "\n",
    "def smooth_emission_MLE(data: list[list[tuple[str, str]]], k: int = 3) -> dict:\n",
    "    data = smooth(data, k)\n",
    "    res = emission_mle(data)\n",
    "    return res\n",
    "\n",
    "\n",
    "def predict(inp_data, out_file, emission):\n",
    "    words = set()\n",
    "    res = []\n",
    "    UNK = \"#UNK#\"\n",
    "    def_tag = max(emission.keys(), key=lambda tag: emission[tag].get(UNK, 0))\n",
    "\n",
    "    for tag in emission:\n",
    "        words |= set(emission[tag].keys())\n",
    "\n",
    "    for seq in inp_data:\n",
    "        pred_seq = []\n",
    "        for word in seq:\n",
    "            pred_tag = max(emission.keys(), key = lambda tag: emission[tag].get(word, 0)) if word in words else def_tag\n",
    "            pred_seq.append((word, pred_tag))\n",
    "        res.append(pred_seq)\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for seq in res:\n",
    "            for word, tag in seq:\n",
    "                f.write(f\"{word} {tag}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "predict(dev_in_data, \"EN/dev.p2.out\", smooth_emission_MLE(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f18b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_mle(data):\n",
    "    tags = {}\n",
    "    count = {}\n",
    "\n",
    "    START_S = \"START\"\n",
    "    STOP_S = \"STOP\"\n",
    "\n",
    "    for seq in data:\n",
    "        prev_state = START_S\n",
    "        for _, curr_state in seq:\n",
    "            if prev_state not in tags:\n",
    "                tags[prev_state] = {}\n",
    "            tags[prev_state][curr_state] = tags[prev_state].get(curr_state, 0) + 1\n",
    "            count[prev_state] = count.get(prev_state, 0) + 1\n",
    "            prev_state = curr_state\n",
    "\n",
    "        if prev_state not in tags:\n",
    "            tags[prev_state] = {}\n",
    "\n",
    "        tags[prev_state][STOP_S] = tags[prev_state].get(STOP_S, 0) + 1\n",
    "\n",
    "    for tag in tags:\n",
    "        for transit_tag in tags[tag]:\n",
    "            tags[tag][transit_tag] /= count[tag]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e467916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(inp_data, words):\n",
    "    UNK = \"#UNK#\"\n",
    "\n",
    "    for i in range(len(inp_data)):\n",
    "        if inp_data[i] not in words:\n",
    "            inp_data[i] = UNK\n",
    "\n",
    "    return inp_data\n",
    "\n",
    "def viterbi(inp_data: list[str], a: dict, b: dict) -> list:\n",
    "\n",
    "    res = []\n",
    "\n",
    "    START_S = \"START\"\n",
    "    STOP_S = \"STOP\"\n",
    "\n",
    "    states = list(b.keys())\n",
    "    words = set(word for tag in b for word in b[tag])\n",
    "    data = clean_data(inp_data, words)\n",
    "\n",
    "    N = len(data)\n",
    "    T = len(states)\n",
    "\n",
    "    # init score matrix (hold scores from start (0) -> 1 to n -> (not including stop (n+1))\n",
    "    score_m = [[0] * T for _ in range(N)] \n",
    "    backpointer = [[0] * T for _ in range(N)]\n",
    "\n",
    "    # start of sequence\n",
    "    for t in range(T):\n",
    "        score_m[0][t] = a[START_S].get(states[t], 0) * b[states[t]].get(data[0], 0)\n",
    "\n",
    "    # recurse for scores\n",
    "    for j in range(1, N):\n",
    "        for t in range(T):\n",
    "            best_score = 0\n",
    "            best_state = 0\n",
    "            for s in range(T):\n",
    "                curr_score = score_m[j-1][s] * a[states[s]].get(states[t], 0) * b[states[t]].get(data[j], 0)\n",
    "                if curr_score > best_score:\n",
    "                    best_score = curr_score\n",
    "                    best_state = s\n",
    "            score_m[j][t] = best_score\n",
    "            backpointer[j][t] = best_state\n",
    "\n",
    "    # end of sequence\n",
    "    last_best_score = 0\n",
    "    last_state_index = 0\n",
    "    for t in range(len(states)):\n",
    "        curr_score = score_m[N-1][t] * a[states[t]].get(STOP_S, 0)\n",
    "        if curr_score > last_best_score:\n",
    "            last_best_score = curr_score\n",
    "            last_state_index = t\n",
    "\n",
    "    res.insert(0, states[last_state_index])\n",
    "\n",
    "    # backtracking\n",
    "    for j in range(N-1, 0, -1):\n",
    "        best_score = 0\n",
    "        probable_state = 0\n",
    "        for t in range(T):\n",
    "            curr_score = score_m[j][t] * a[states[t]].get(res[0], 0)\n",
    "            if curr_score > best_score:\n",
    "                best_score = curr_score\n",
    "                probable_state = backpointer[j][t]\n",
    "        res.insert(0, states[probable_state])\n",
    "\n",
    "    return res\n",
    "\n",
    "def predict_viterbi(inp_data: list, train_data: list[list[tuple[str, str]]], out_file: str):\n",
    "    TAB_E = \"#TAB#\"\n",
    "    START_S = \"START\"\n",
    "    STOP_S = \"STOP\"\n",
    "\n",
    "    # init params\n",
    "    a = transition_mle(train_data)\n",
    "    b = smooth_emission_MLE(train_data)\n",
    "\n",
    "    res = []\n",
    "    for ob_seq in inp_data:\n",
    "        pred_state_seq = viterbi(ob_seq, a, b)\n",
    "        res.append(pred_state_seq)\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for ob_seq, seq in zip(inp_data, res):\n",
    "            for word, tag in zip(ob_seq, seq):\n",
    "                f.write(f\"{word} {tag}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "predict_viterbi(dev_in_data, train_data, \"EN/dev.p2.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ebd30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b4a046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
